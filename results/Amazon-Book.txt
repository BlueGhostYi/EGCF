PyTorch Implementation for Embedding-less Graph Collaborative Filtering
--------------------------------------------------------------------------------
	 Step 1: General parameter setting reading...
--------------------------------------------------------------------------------
	 Step 2: Select model...
	 Step 3.1: Loading configuration file...
	 Step 3.2: Loading dataset file...
	 num_users: 52643
	 num_items: 91599
	 num_nodes: 144242
	 num_train: 2380726
	 num_test:  603382
	 sparisty:  0.999381153165515
--------------------------------------------------------------------------------
	 Step 3.3: Init the Recommendation Model:
	 Adjacency matrix loading completed.
	 Adjacency matrix loading completed.
	 model:  EGCF
	 dataset_path : ./dataset/
	 dataset : amazon-book
	 top_K : [20, 40]
	 training_epochs : 30
	 early_stopping : 10
	 embedding_size : 64
	 batch_size : 2048
	 test_batch_size : 2048
	 learn_rate : 0.001
	 reg_lambda : 0.0001
	 GCN_layer : 3
	 ssl_lambda : 0.3
	 temperature : 0.1
	 mode : parallel
	 sparsity_test : 0
--------------------------------------------------------------------------------
	 Step 4: Model training and testing process:
	 Epoch:    1| train time: 60.063 | train_loss: 2.227428 = 0.692041 + 2e-06 + 1.535385
	 Recall: [0.05101839 0.0804044 ] NDCG: [0.04136133 0.05232596] Pre: [0.02182151 0.01765287]
	 Epoch:    2| train time: 59.085 | train_loss: 2.128784 = 0.690061 + 5e-06 + 1.438717
	 Recall: [0.04997137 0.07919046] NDCG: [0.04060233 0.05152617] Pre: [0.02140645 0.01742444]
	 Epoch:    3| train time: 58.888 | train_loss: 2.110433 = 0.687511 + 9e-06 + 1.422913
	 Recall: [0.0395195  0.06191529] NDCG: [0.0322254  0.04057649] Pre: [0.01675816 0.01349277]
	 Epoch:    4| train time: 58.818 | train_loss: 2.098124 = 0.683794 + 1.4e-05 + 1.414316
	 Recall: [0.02887274 0.04580302] NDCG: [0.02365159 0.02998384] Pre: [0.01223145 0.00997901]
	 Epoch:    5| train time: 59.501 | train_loss: 2.086363 = 0.678157 + 2.2e-05 + 1.408184
	 Recall: [0.019131   0.03139752] NDCG: [0.01559931 0.0201798 ] Pre: [0.00815208 0.00683234]
	 Epoch:    6| train time: 59.274 | train_loss: 2.073949 = 0.670629 + 3.3e-05 + 1.403287
	 Recall: [0.01742144 0.02907753] NDCG: [0.01430477 0.01868988] Pre: [0.00746348 0.00638831]
	 Epoch:    7| train time: 59.373 | train_loss: 2.059249 = 0.660022 + 4.8e-05 + 1.399179
	 Recall: [0.01861218 0.03028053] NDCG: [0.01511011 0.01949741] Pre: [0.00798302 0.00669605]
	 Epoch:    8| train time: 59.067 | train_loss: 2.039843 = 0.643344 + 7e-05 + 1.396429
	 Recall: [0.02125596 0.03489219] NDCG: [0.01743484 0.02254684] Pre: [0.00911897 0.00766674]
	 Epoch:    9| train time: 59.241 | train_loss: 2.011453 = 0.61577 + 0.000106 + 1.395576
	 Recall: [0.02649209 0.04260958] NDCG: [0.0216654  0.02769924] Pre: [0.0112845  0.00932508]
	 Epoch:   10| train time: 59.152 | train_loss: 1.969245 = 0.572089 + 0.000166 + 1.39699
	 Recall: [0.03440753 0.05449073] NDCG: [0.02811957 0.03558301] Pre: [0.01476455 0.01198402]
	 Epoch:   11| train time: 59.090 | train_loss: 1.907327 = 0.505235 + 0.000266 + 1.401826
	 Recall: [0.04325858 0.06826261] NDCG: [0.03531168 0.04460094] Pre: [0.01854947 0.01502431]
	 Epoch:   12| train time: 59.079 | train_loss: 1.824274 = 0.414539 + 0.000428 + 1.409307
	 Recall: [0.04903705 0.07732494] NDCG: [0.0398015  0.05037451] Pre: [0.02096955 0.01699751]
	 Epoch:   13| train time: 60.256 | train_loss: 1.734864 = 0.319478 + 0.000664 + 1.414722
	 Recall: [0.05185197 0.08234782] NDCG: [0.04181492 0.05325172] Pre: [0.02210645 0.01801332]
	 Epoch:   14| train time: 60.781 | train_loss: 1.657458 = 0.241337 + 0.000963 + 1.415158
	 Recall: [0.05317662 0.08476677] NDCG: [0.04255141 0.05442599] Pre: [0.0225595  0.01847492]
	 Epoch:   15| train time: 59.931 | train_loss: 1.598889 = 0.185605 + 0.001301 + 1.411983
	 Recall: [0.05375703 0.08577482] NDCG: [0.04274625 0.05478727] Pre: [0.02274092 0.01863971]
	 Epoch:   16| train time: 60.533 | train_loss: 1.556714 = 0.147549 + 0.001659 + 1.407507
	 Recall: [0.05400787 0.08597693] NDCG: [0.04281716 0.05480006] Pre: [0.02272002 0.01863686]
	 Epoch:   17| train time: 60.084 | train_loss: 1.526685 = 0.121601 + 0.002018 + 1.403066
	 Recall: [0.05373813 0.08599512] NDCG: [0.04257064 0.05474788] Pre: [0.0225842  0.01862641]
	 Epoch:   18| train time: 59.146 | train_loss: 1.505039 = 0.103545 + 0.002371 + 1.399123
	 Recall: [0.05371324 0.08576185] NDCG: [0.04249112 0.05460127] Pre: [0.02253386 0.01857844]
	 Epoch:   19| train time: 58.934 | train_loss: 1.489017 = 0.090339 + 0.00271 + 1.395969
	 Recall: [0.05339725 0.08536715] NDCG: [0.04224519 0.05431736] Pre: [0.02238949 0.01846114]
	 Epoch:   20| train time: 59.088 | train_loss: 1.476606 = 0.080365 + 0.003034 + 1.393207
	 Recall: [0.0532054  0.08486709] NDCG: [0.04204054 0.05400256] Pre: [0.02229166 0.01835049]
	 Epoch:   21| train time: 59.138 | train_loss: 1.467662 = 0.073046 + 0.003343 + 1.391273
	 Recall: [0.05292527 0.08447503] NDCG: [0.04186079 0.05379587] Pre: [0.02215489 0.01826834]
	 Epoch:   22| train time: 58.935 | train_loss: 1.460356 = 0.067078 + 0.003634 + 1.389643
	 Recall: [0.05276822 0.08414285] NDCG: [0.04172351 0.0535844 ] Pre: [0.02211025 0.01819805]
	 Epoch:   23| train time: 59.087 | train_loss: 1.454128 = 0.062213 + 0.003912 + 1.388003
	 Recall: [0.05252199 0.08377967] NDCG: [0.04154798 0.05334791] Pre: [0.02202192 0.01810782]
	 Epoch:   24| train time: 58.885 | train_loss: 1.449261 = 0.058217 + 0.004173 + 1.386871
	 Recall: [0.05243938 0.08355796] NDCG: [0.04143881 0.05318449] Pre: [0.02196018 0.01805131]
	 Epoch:   25| train time: 59.173 | train_loss: 1.445531 = 0.055094 + 0.004423 + 1.386015
	 Recall: [0.05224723 0.08324073] NDCG: [0.04127782 0.05297556] Pre: [0.0219051  0.01800477]
	 Epoch:   26| train time: 58.847 | train_loss: 1.441864 = 0.052225 + 0.004658 + 1.384982
	 Recall: [0.05200711 0.08307944] NDCG: [0.04111722 0.05282969] Pre: [0.02181202 0.01794873]
	 Epoch:   27| train time: 59.088 | train_loss: 1.438891 = 0.04963 + 0.004882 + 1.384379
	 Recall: [0.05181457 0.08283496] NDCG: [0.04099425 0.05269865] Pre: [0.02173603 0.01791169]
	 Epoch:   28| train time: 59.938 | train_loss: 1.436693 = 0.04785 + 0.005096 + 1.383747
	 Recall: [0.05161307 0.08242105] NDCG: [0.04080231 0.052433  ] Pre: [0.02163725 0.01782193]
	 Epoch:   29| train time: 60.316 | train_loss: 1.434312 = 0.045903 + 0.005299 + 1.38311
	 Recall: [0.0515463 0.0821465] NDCG: [0.04073365 0.05231267] Pre: [0.02158407 0.01778821]
	 Epoch:   30| train time: 60.425 | train_loss: 1.432247 = 0.044186 + 0.005494 + 1.382568
	 Recall: [0.05115318 0.08187196] NDCG: [0.04052239 0.05214162] Pre: [0.0214511 0.0177279]
	 Model training process completed.
	 best epoch: 16
	 best recall: 0.054007868727151184